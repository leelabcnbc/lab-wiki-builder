{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel for two sets\n",
    "\n",
    "## Pyramid matching kernel\n",
    "\n",
    "K. Grauman and T. Darrell, “The pyramid match kernel: discriminative classification with sets of image features,” presented at the Tenth IEEE International Conference on Computer Vision (ICCV'05), 2005, vol. 2, pp. 1458–1465.\n",
    "\n",
    "Great idea to compare two bags of features.\n",
    "\n",
    "Some details.\n",
    "\n",
    "In 3.3, the Mercer's condition is proved for $\\tilde{K}$, not $K$. But this should not matter, since we already get a $\\phi(x)$ for $\\tilde{K}$, then we can define the $\\phi'(x)$ for $K$ as $\\phi(x) / \\sqrt{\\tilde{K}(x,x)}$.\n",
    "\n",
    "[1]\tK. Grauman and T. Darrell, “The pyramid match kernel: discriminative classification with sets of image features,” presented at the Tenth IEEE International Conference on Computer Vision (ICCV'05), 2005, vol. 2, pp. 1458–1465.\n",
    "\n",
    "Other notes\n",
    "\n",
    "* p.1458: However, conventional kernel-based algorithms are designed to operate on fixed-length vector inputs, where each vector entry corresponds to a particular global attribute for that instance; the commonly used general-purpose kernels defined on Rn inputs (e.g., Gaussian RBF, polynomial) are not applicable in the space of vector sets. -- Highlighted Feb 15, 2017\n",
    "* p.1458: The similarity measured by the pyramid match approximates the similarity measured by the optimal correspon- -- Highlighted Feb 15, 2017\n",
    "* p.1459: Because it does not penalize the presence of superfluous data points, the proposed kernel is robust to clutter. -- Highlighted Feb 15, 2017\n",
    "* p.1459: Several researchers have designed similarity measures that operate on sets of unordered features. -- Highlighted Feb 15, 2017\n",
    "* p.1460: match each feature in a set independently, ignoring potentially useful co-occurrence information. In contrast, our kernel captures the joint statistics of co-occurring features by matching them concurrently as a set. -- Highlighted Feb 15, 2017\n",
    "* p.1461: In other    words, Ψ(x) is a vector of concatenated histograms, where each subsequent component histogram has bins that double in size (in all d dimensions) compared to the previous one. The bins in the finest-level histogram H−1 are small enough that each d-dimensional data point from sets in X falls into its own bin, and then the bin size increases until all data points from sets in X fall into a single bin at level L. -- Highlighted Feb 15, 2017\n",
    "* p.1461: Note that the kernel is not searching explicitly for similar points – it never computes distances between the vectors in each set. Instead, it simply uses the change in intersection values at each histogram level to count the matches as they occur. -- Highlighted Feb 15, 2017\n",
    "* p.1462: Thus, the numberof new matches induced at level i is weighted by 1 to re2iflect the (worst-case) similarity of points matched at that level. -- Highlighted Feb 15, 2017\n",
    "* p.1462: With variable cardinalities no similar proof is available, but we show empirically below that the intersection of multiresolution histograms approximates the best partial matching both in simulation and in practice. -- Highlighted Feb 15, 2017\n",
    "* p.1462: Intuitively, this means that similarity between vectors (features in y and z)) at a finer resolution – where features are most distinct – is rewarded more heavily than similarity between vectors at a coarser level. -- Highlighted Feb 15, 2017\n",
    "* p.1462: Intersec-tion over the pyramid with weights set to w = 1 then -- Highlighted Feb 15, 2017\n",
    "* p.1464: Allowing the same run-time -- Highlighted Feb 15, 2017\n",
    "\n",
    "~~~\n",
    "@inproceedings{Grauman:2005iu,\n",
    "author = {Grauman, Kristen and Darrell, Trevor},\n",
    "title = {{The pyramid match kernel: discriminative classification with sets of image features}},\n",
    "booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05)},\n",
    "year = {2005},\n",
    "pages = {1458--1465},\n",
    "publisher = {IEEE},\n",
    "annote = {Great idea to compare two bags of features.\n",
    "\n",
    "Some details.\n",
    "\n",
    "In 3.3, the Mercer's condition is proved for K tilde, not K. But this should not matter, since we already get a \\phi for K tilde (P), then we can define the \\phi'(P) for K as \\phi(P) / \\sqrt{K tilde (P,P)}.},\n",
    "keywords = {classics},\n",
    "doi = {10.1109/ICCV.2005.239},\n",
    "isbn = {0-7695-2334-X},\n",
    "read = {Yes},\n",
    "rating = {5},\n",
    "date-added = {2017-02-15T04:36:31GMT},\n",
    "date-modified = {2017-02-17T20:20:26GMT},\n",
    "url = {http://ieeexplore.ieee.org/document/1544890/},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2005/Grauman/ICCV%202005%202005%20Grauman.pdf},\n",
    "file = {{ICCV 2005 2005 Grauman.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2005/Grauman/ICCV 2005 2005 Grauman.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/doi/10.1109/ICCV.2005.239}}\n",
    "}\n",
    "~~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
